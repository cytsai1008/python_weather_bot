import google.generativeai as genai
import os
from typing import Dict, Optional


class GeminiService:
    """Service to generate weather-based suggestions using Gemini AI"""

    def __init__(self):
        self.api_key = os.getenv('GEMINI_API_KEY')
        if not self.api_key:
            raise ValueError("è«‹è¨­å®š GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸")

        genai.configure(api_key=self.api_key)
        self.model = genai.GenerativeModel('gemini-2.5-flash')

    async def get_weather_suggestions(self, location: str, weather_data: Dict) -> Optional[str]:
        """
        Generate personalized suggestions based on weather data

        Args:
            location: Location name
            weather_data: Dictionary containing weather information

        Returns:
            String with AI-generated suggestions or None if error
        """
        try:
            # Construct prompt for Gemini
            prompt = self._create_prompt(location, weather_data)

            # Generate response
            response = await self._generate_async(prompt)

            # If Gemini fails, use simple suggestions as fallback
            if response is None:
                print("Gemini failed, using simple suggestions fallback")
                return self.get_simple_suggestion(weather_data)

            return response

        except Exception as e:
            print(f"Error generating suggestions: {e}")
            # Use simple suggestions as fallback
            return self.get_simple_suggestion(weather_data)

    def _create_prompt(self, location: str, weather_data: Dict) -> str:
        """Create a detailed prompt for Gemini"""

        high_temp = weather_data.get('high_temp', 'N/A')
        low_temp = weather_data.get('low_temp', 'N/A')
        pop = weather_data.get('pop', 'N/A')
        weather_desc = weather_data.get('weather_description', 'N/A')
        comfort = weather_data.get('comfort', 'N/A')

        prompt = f"""ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ°£è±¡é¡§å•å’Œç”Ÿæ´»å»ºè­°å°ˆå®¶ã€‚æ ¹æ“šä»¥ä¸‹çš„å¤©æ°£è³‡æ–™ï¼Œè«‹ç”¨ç¹é«”ä¸­æ–‡æä¾›ç°¡æ½”å¯¦ç”¨çš„ç”Ÿæ´»å»ºè­°ã€‚

åœ°é»: {location}
é«˜æº«: {high_temp}Â°C
ä½æº«: {low_temp}Â°C
é™é›¨æ©Ÿç‡: {pop}%
å¤©æ°£ç‹€æ³: {weather_desc}
èˆ’é©åº¦: {comfort}

è«‹æä¾›ä»¥ä¸‹æ–¹é¢çš„å»ºè­°ï¼ˆä¿æŒç°¡æ½”ï¼Œæ¯é …2-3è¡Œï¼‰ï¼š
1. ğŸŒ¡ï¸ é«”æ„Ÿèˆ‡èˆ’é©åº¦
2. ğŸ‘” ç©¿è‘—å»ºè­°
3. â˜‚ï¸ å¤–å‡ºæº–å‚™
4. ğŸ’¡ ç”Ÿæ´»å°æç¤º

è«‹ç”¨å‹å–„ã€å£èªåŒ–çš„æ–¹å¼å›ç­”ï¼Œä¸¦ä½¿ç”¨é©ç•¶çš„emojiè®“å…§å®¹æ›´ç”Ÿå‹•ã€‚ä¿æŒå›ç­”ç°¡æ½”æ˜ç­ï¼Œç¸½é•·åº¦æ§åˆ¶åœ¨250å­—ä»¥å…§ã€‚"""

        return prompt

    async def _generate_async(self, prompt: str) -> str:
        """Generate response asynchronously"""
        import asyncio

        try:
            # Run the synchronous Gemini API call in a thread pool
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                lambda: self.model.generate_content(
                    prompt,
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.7,
                        top_p=0.9,
                        top_k=40,
                        max_output_tokens=2000,  # Increased for longer responses
                    )
                )
            )

            # Check if response has valid content
            if not response.candidates:
                print("Gemini: No candidates returned")
                return "ç„¡æ³•ç”Ÿæˆå»ºè­°ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

            candidate = response.candidates[0]

            # Check finish reason
            # 1 = STOP (success), 2 = MAX_TOKENS, 3 = SAFETY, 4 = RECITATION, 5 = OTHER
            if candidate.finish_reason == 3:  # SAFETY
                print("Gemini: Response blocked by safety filters")
                return "æŠ±æ­‰ï¼Œç„¡æ³•ç‚ºæ­¤å¤©æ°£ç”Ÿæˆå»ºè­°ã€‚"

            if candidate.finish_reason == 2:  # MAX_TOKENS
                print("Gemini: Response truncated (max tokens)")
                # Still try to return partial response

            # Try to get text from response
            try:
                if response.text:
                    return response.text.strip()
            except ValueError:
                # response.text failed, try to extract from parts
                if candidate.content and candidate.content.parts:
                    text_parts = [part.text for part in candidate.content.parts if hasattr(part, 'text')]
                    if text_parts:
                        return ''.join(text_parts).strip()

            return "ç„¡æ³•ç”Ÿæˆå»ºè­°ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

        except Exception as e:
            print(f"Gemini API error: {e}")
            # Return simple suggestion as fallback
            return None  # Signal to use fallback

    def get_simple_suggestion(self, weather_data: Dict) -> str:
        """
        Fallback method to provide simple suggestions without AI
        """
        high_temp = int(weather_data.get('high_temp', 25))
        pop = int(weather_data.get('pop', 0))

        suggestions = []

        # Temperature-based suggestions
        if high_temp >= 30:
            suggestions.append("ğŸŒ¡ï¸ å¤©æ°£ç‚ç†±ï¼Œè¨˜å¾—å¤šè£œå……æ°´åˆ†")
            suggestions.append("ğŸ‘• å»ºè­°ç©¿è‘—è¼•è–„é€æ°£çš„è¡£ç‰©")
        elif high_temp >= 25:
            suggestions.append("ğŸŒ¡ï¸ å¤©æ°£æº«æš–èˆ’é©")
            suggestions.append("ğŸ‘• çŸ­è¢–æˆ–è–„é•·è¢–å³å¯")
        elif high_temp >= 20:
            suggestions.append("ğŸŒ¡ï¸ æ°£æº«é©ä¸­ï¼Œæ—©æ™šç¨æ¶¼")
            suggestions.append("ğŸ‘” å»ºè­°æ´‹è”¥å¼ç©¿æ­")
        else:
            suggestions.append("ğŸŒ¡ï¸ å¤©æ°£åå†·ï¼Œæ³¨æ„ä¿æš–")
            suggestions.append("ğŸ§¥ å»ºè­°ç©¿è‘—å¤–å¥—æˆ–åšè¡£ç‰©")

        # Rain-based suggestions
        if pop >= 70:
            suggestions.append("â˜‚ï¸ é™é›¨æ©Ÿç‡é«˜ï¼Œå‹™å¿…æ”œå¸¶é›¨å…·")
        elif pop >= 30:
            suggestions.append("â˜‚ï¸ å¯èƒ½ä¸‹é›¨ï¼Œå»ºè­°å¸¶å‚˜å‚™ç”¨")

        return "\n".join(suggestions)
